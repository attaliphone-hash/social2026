import os
from dotenv import load_dotenv
from pinecone import Pinecone
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_pinecone import PineconeVectorStore

load_dotenv()

# Config
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
INDEX_NAME = "expert-social"

pc = Pinecone(api_key=PINECONE_API_KEY)
index = pc.Index(INDEX_NAME)
embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004")

def update_dynamic_docs():
    print("\n" + "="*60)
    print("‚ö° MISE √Ä JOUR CIBL√âE (JURISPRUDENCE & CHIFFRES)")
    print("="*60)
    print("‚ÑπÔ∏è  MODE : Chirurgical")
    print("üõ°Ô∏è  S√âCURIT√â : Le 'Code du Travail' et 'Code S√©cu' NE SERONT PAS TOUCH√âS.")
    print("-" * 60)

    # 1. Suppression des anciens REF et DOC uniquement
    print("\n1Ô∏è‚É£  NETTOYAGE PR√âALABLE")
    print("   üßπ Suppression des anciennes versions de REF (Bar√®mes) et DOC (Jurisprudence)...")
    try:
        # On filtre par cat√©gorie pour ne pas toucher aux CODES
        index.delete(filter={"category": {"$in": ["REF", "DOC"]}})
        print("   ‚úÖ Nettoyage termin√© (Les CODES sont rest√©s intacts).")
    except Exception as e:
        print(f"   ‚ö†Ô∏è Erreur nettoyage: {e}")

    # 2. Chargement des nouveaux fichiers
    print("\n2Ô∏è‚É£  LECTURE DES FICHIERS LOCAUX")
    documents = []
    data_path = "./data_clean"
    
    count_skipped = 0
    
    for root, dirs, files in os.walk(data_path):
        for filename in files:
            filepath = os.path.join(root, filename)
            
            # CAS 1 : C'est un fichier √† mettre √† jour (REF ou DOC)
            if filename.startswith("REF_") or filename.startswith("DOC_"):
                category = "REF" if filename.startswith("REF_") else "DOC"
                try:
                    if filename.endswith(".pdf"):
                        loader = PyPDFLoader(filepath)
                    else:
                        loader = TextLoader(filepath, encoding="utf-8")
                    
                    docs = loader.load()
                    for d in docs:
                        d.metadata["source"] = filename
                        d.metadata["category"] = category
                    documents.extend(docs)
                    print(f"   üì• Ajout√© au panier : {filename}")
                except Exception as e:
                    print(f"   ‚ùå Erreur lecture {filename}: {e}")
            
            # CAS 2 : C'est un fichier syst√®me (DS_Store, gitkeep) -> On ignore silencieusement
            elif filename.startswith("."):
                continue
                
            # CAS 3 : C'est un autre fichier (Probablement un CODE ou autre) -> On le prot√®ge
            else:
                count_skipped += 1
                # On l'affiche en gris (ou juste un message simple)
                print(f"   üõ°Ô∏è  PROTECTION (Ignor√©) : {filename}")

    if not documents:
        print("\n‚ùå Aucun fichier REF_ ou DOC_ trouv√© √† mettre √† jour.")
        return

    # 3. D√©coupage
    print(f"\n3Ô∏è‚É£  D√âCOUPAGE INTELLIGENT")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    chunks = text_splitter.split_documents(documents)
    print(f"   ‚úÇÔ∏è  Pr√©paration de {len(chunks)} fragments de texte.")

    # 4. Injection
    print("\n4Ô∏è‚É£  ENVOI VERS LE CERVEAU (PINECONE)")
    print("   üß† Synchronisation en cours...")
    PineconeVectorStore.from_documents(
        chunks, 
        embeddings, 
        index_name=INDEX_NAME
    )
    
    print("\n" + "="*60)
    print("üéâ SUCC√àS : BASE DE CONNAISSANCES MISE √Ä JOUR !")
    print(f"üìä Bilan : {len(chunks)} blocs mis √† jour | {count_skipped} fichiers prot√©g√©s (Codes).")
    print("="*60 + "\n")

if __name__ == "__main__":
    update_dynamic_docs()