import os
import time
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_pinecone import PineconeVectorStore
from langchain_text_splitters import RecursiveCharacterTextSplitter
from pinecone import Pinecone

# 1. Chargement Config
load_dotenv()
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_INDEX_NAME = "expert-social"
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY") 

# --- S√âCURIT√â CRITIQUE (AJOUT√âE) ---
if not PINECONE_API_KEY or not GOOGLE_API_KEY:
    print("‚ùå ERREUR CRITIQUE : Cl√©s API manquantes dans le fichier .env")
    print("   Arr√™t imm√©diat pour prot√©ger la base de donn√©es.")
    exit()

# Dossier des donn√©es
DATA_PATH = "data_clean"

# 2. Initialisation Pinecone
print("üöÄ D√âMARRAGE DE LA REFONTE TOTALE (SMART SPLIT / 3072d)...")
try:
    pc = Pinecone(api_key=PINECONE_API_KEY)
    index = pc.Index(PINECONE_INDEX_NAME)
    
    # Test de connexion avant suppression
    index.describe_index_stats()
    print("‚úÖ Connexion Pinecone valid√©e.")
except Exception as e:
    print(f"‚ùå Impossible de se connecter √† Pinecone : {e}")
    exit()

print("üóëÔ∏è  SUPPRESSION TOTALE de l'ancienne m√©moire...")
try:
    index.delete(delete_all=True)
    print("‚úÖ M√©moire vierge.")
    time.sleep(5) # Pause vitale pour Pinecone apr√®s un delete_all
except Exception as e:
    print(f"‚ö†Ô∏è Index d√©j√† vide ou erreur: {e}")

# 3. Le D√©coupeur Juridique (Smart Splitter)
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1200,       
    chunk_overlap=200,     
    separators=["Article ", "\n\n", ". ", " "]
)

documents = []
stats = {"CODES": 0, "REF": 0, "DOC": 0}

print(f"üìÇ Scan des fichiers sources dans '{DATA_PATH}'...")

VALID_EXTS = [".pdf", ".txt"]

if not os.path.exists(DATA_PATH):
    print(f"‚ùå ERREUR : Le dossier '{DATA_PATH}' n'existe pas !")
    exit()

for root, dirs, files in os.walk(DATA_PATH):
    if "venv" in root or ".git" in root: continue
    
    for filename in files:
        filepath = os.path.join(root, filename)
        
        category = None
        if filename.startswith("FULL_") or "Code" in filename: category = "CODES" 
        elif filename.startswith("REF_"): category = "REF"   
        elif filename.startswith("DOC_"): category = "DOC"   
        
        if category and any(filename.lower().endswith(e) for e in VALID_EXTS):
            print(f"   -> Lecture de : {filename} ({category})")
            if category in stats: stats[category] += 1
            
            try:
                docs = []
                if filename.lower().endswith(".pdf"):
                    loader = PyPDFLoader(filepath)
                    docs = loader.load()
                elif filename.lower().endswith(".txt"):
                    loader = TextLoader(filepath, encoding="utf-8")
                    docs = loader.load()
                
                for d in docs:
                    d.metadata["source"] = filename
                    d.metadata["category"] = category
                    if category == "CODES":
                        d.metadata["importance"] = "high"
                
                documents.extend(docs)
                
            except Exception as e:
                print(f"   ‚ùå Erreur lecture {filename}: {e}")

if not documents:
    print("‚ùå ALERTE : Aucun fichier (FULL_, REF_, DOC_) trouv√© !")
    exit()

print(f"\nüìä Bilan : {stats['CODES']} Codes Complets | {stats['REF']} Bar√®mes | {stats['DOC']} Docs")

# 4. Traitement
print(f"\n‚úÇÔ∏è  D√©coupage intelligent (Cela peut prendre 1-2 minutes)...")
final_chunks = text_splitter.split_documents(documents)
print(f"üß© R√âSULTAT : {len(final_chunks)} blocs de connaissance haute d√©finition.")

# 5. Injection
print("üß† Injection dans Pinecone (C'est le moment critique)...")

# Configuration explicite (S√©curis√©e)
embeddings = GoogleGenerativeAIEmbeddings(
    model="models/gemini-embedding-001",
    google_api_key=GOOGLE_API_KEY, # Cl√© explicite
    task_type="retrieval_document"
)

batch_size = 50 
total_batches = len(final_chunks) // batch_size + 1

for i in range(0, len(final_chunks), batch_size):
    batch = final_chunks[i:i + batch_size]
    try:
        PineconeVectorStore.from_documents(batch, embeddings, index_name=PINECONE_INDEX_NAME)
        percent = round((i / len(final_chunks)) * 100)
        print(f"   ‚úì Progression : {percent}% (Lot {i//batch_size + 1}/{total_batches})")
    except Exception as e:
        print(f"   ‚ùå Erreur lot {i}: {e}")
        time.sleep(5) 

print("\nüéâ MISSION ACCOMPLIE. Base reconstruite en 3072 dimensions.")